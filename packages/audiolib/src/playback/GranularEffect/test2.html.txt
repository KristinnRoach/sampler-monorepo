<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Basic Granular Synthesis Test</title>
    <style>
      body {
        font-family: sans-serif;
        max-width: 600px;
        margin: 0 auto;
        padding: 20px;
      }
      .controls {
        margin: 20px 0;
      }
      .slider-container {
        margin: 10px 0;
      }
    </style>
  </head>
  <body>
    <h1>Granular Synthesis Test</h1>
    <p>Press 'p' to play sound</p>

    <div class="controls">
      <div class="slider-container">
        <label for="holdSlider">Hold: <span id="holdValue">7000</span></label>
        <input type="range" id="holdSlider" min="0" max="20000" value="7000" />
      </div>
    </div>

    <script>
      // AudioWorklet processor code
      const workletCode = `
    class GranularEffectProcessor extends AudioWorkletProcessor {
      static get parameterDescriptors() {
        return [
          {
            name: 'hold',
            defaultValue: 7000,
            minValue: 0,
            maxValue: 44100,
            automationRate: 'a-rate',
          }
        ];
      }

      constructor() {
        super();
        this.sampleBuffer = null;
        
        this.port.onmessage = (event) => {
          if (event.data.type === 'buffer') {
            this.sampleBuffer = new Float32Array(event.data.buffer);
          }
        };
      }

      process(inputs, outputs, parameters) {
        const input = inputs[0];
        const output = outputs[0];
        
        // If we have input, process it with granular effect
        if (input.length > 0) {
          const hold = parameters.hold[0];
          
          for (let channel = 0; channel < Math.min(input.length, output.length); channel++) {
            const inputChannel = input[channel];
            const outputChannel = output[channel];
            
            for (let i = 0; i < outputChannel.length; i++) {
              // Apply a simple effect based on hold value
              // Higher hold = more sustain (simplified)
              const sustainFactor = Math.min(1, hold / 10000);
              outputChannel[i] = inputChannel[i] * sustainFactor;
            }
          }
        } else {
          // Clear output if no input
          for (let channel = 0; channel < output.length; channel++) {
            const outputChannel = output[channel];
            outputChannel.fill(0);
          }
        }
        
        return true;
      }
    }

    registerProcessor('granular-effect-processor', GranularEffectProcessor);
    `;

      // Main script
      let audioContext;
      let sharedWorkletNode;
      let audioBuffer;
      let activeSource;

      async function setupAudio() {
        try {
          audioContext = new AudioContext();

          // Create a blob from the processor code
          const blob = new Blob([workletCode], {
            type: 'application/javascript',
          });
          const workletUrl = URL.createObjectURL(blob);

          // Load the processor
          await audioContext.audioWorklet.addModule(workletUrl);

          // Create shared worklet node
          sharedWorkletNode = new AudioWorkletNode(
            audioContext,
            'granular-effect-processor'
          );
          sharedWorkletNode.connect(audioContext.destination);

          // Create a simple sine wave buffer
          audioBuffer = createSineWaveBuffer(audioContext, 440, 2);

          console.log('Audio setup complete');
        } catch (error) {
          console.error('Error setting up audio:', error);
        }
      }

      function createSineWaveBuffer(context, frequency, duration) {
        const sampleRate = context.sampleRate;
        const length = sampleRate * duration;
        const buffer = context.createBuffer(1, length, sampleRate);
        const channel = buffer.getChannelData(0);

        for (let i = 0; i < length; i++) {
          channel[i] = Math.sin((2 * Math.PI * frequency * i) / sampleRate);
        }

        return buffer;
      }

      function playSound() {
        if (!audioContext) {
          setupAudio().then(playSound);
          return;
        }

        if (audioContext.state === 'suspended') {
          audioContext.resume();
        }

        // Stop any currently playing source
        stopSound();

        // Create a new source node and connect to the shared worklet
        activeSource = new AudioBufferSourceNode(audioContext, {
          buffer: audioBuffer,
        });
        activeSource.connect(sharedWorkletNode);

        // Set the hold parameter
        const holdValue = parseInt(document.getElementById('holdSlider').value);
        sharedWorkletNode.parameters
          .get('hold')
          .setValueAtTime(holdValue, audioContext.currentTime);

        // Send the buffer to the processor
        sharedWorkletNode.port.postMessage({
          type: 'buffer',
          buffer: audioBuffer.getChannelData(0),
        });

        // Start the source
        activeSource.start();
      }

      function stopSound() {
        if (activeSource) {
          try {
            activeSource.stop();
          } catch (e) {
            // Ignore errors if source already stopped
          }
          activeSource = null;
        }
      }

      // Set up event listeners
      document.addEventListener('keydown', (event) => {
        if (event.key === 'p' && !event.repeat) {
          playSound();
        }
      });

      document.addEventListener('keyup', (event) => {
        if (event.key === 'p') {
          stopSound();
        }
      });

      const holdSlider = document.getElementById('holdSlider');
      const holdValue = document.getElementById('holdValue');

      holdSlider.addEventListener('input', () => {
        holdValue.textContent = holdSlider.value;

        if (sharedWorkletNode) {
          sharedWorkletNode.parameters
            .get('hold')
            .setValueAtTime(
              parseInt(holdSlider.value),
              audioContext.currentTime
            );
        }
      });

      // Initialize audio when the page loads
      document.addEventListener('DOMContentLoaded', setupAudio);
    </script>
  </body>
</html>
