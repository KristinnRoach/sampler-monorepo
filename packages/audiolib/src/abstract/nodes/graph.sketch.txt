import { NodeID } from '@/types/global';
// abstraction brainstorm:
// everything is a node
// parent === output, child === input
// nodes can contain other nodes
// if they do, should they

interface Root {
  out: NodeID[]; // [], just ctx.destination if root
  in: NodeID[]; // [], empty if leaf
  addNode: (node: Node) => boolean;
  removeNode: (node: Node) => boolean;
}

// Container / Wrapper / Family of connected nodes
interface SubGraph {
  // research suitable datatypes for each graph type
  graphType: 'Chain' | 'DAG' | 'FeedbackLoop'; // |Â "LLRBTree" |
}

// Chain === Array or Linked List, could be abstracted as Edge with weight nr nodes
interface NodeChain extends Node {
  parents: NodeID[];
  nodes: Node[];
}

interface NodeDAG extends Node {
  // DAG === which data type ???
  // nodes: ??? // edges: ???
}

interface AudioLibGraph {
  graphType: 'DAG';
  instruments: SubGraph[];
}

// Nodes that may have no inputs, i.e. children (only outputs) // Individuals
interface LeafNode {
  type: 'Source' | 'Param';
}

// "NativeWebAudio" | "CustomWebWorklet";

// todo: Instrument: Container,
// export default function createNode(
//     type: NodeType
// )

// import { SingleSamplePlayer } from '@/instruments/SingleSample/SingleSamplePlayer_loopController';
// import { VoiceNode } from '@/nodes/voice/VoiceNode';
// import { FlexEventDriven } from './FlexEventDriven';
// import { BaseWorkletNode } from './BaseWorkletNode';

// type WebAudioNode =
//   | AudioNode
//   | AudioBufferSourceNode
//   | AudioParam
//   | AudioWorkletNode
//   | AudioWorkletProcessor;
// // | AudioDestinationNode
// // | AudioScheduledSourceNode
// // | AudioContext
// // | AudioWorkletGlobalScope
// // | AudioListener;

// type CustomNode =
//   | VoiceNode
//   | SingleSamplePlayer
//   | FlexEventDriven
//   | BaseWorkletNode;

// type NodeType = CustomNode | WebAudioNode;
