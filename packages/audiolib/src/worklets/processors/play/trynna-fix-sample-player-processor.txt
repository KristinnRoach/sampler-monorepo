class SamplePlayerProcessor extends AudioWorkletProcessor {
  // ===== PARAMETER DESCRIPTORS =====
  static get parameterDescriptors() {
    return [
      {
        name: 'playbackPosition',
        defaultValue: 0,
        minValue: 0, // ???
        maxValue: 1000, // ???
        automationRate: 'k-rate',
      },
      {
        name: 'envGain',
        defaultValue: 0,
        minValue: 0,
        maxValue: 1,
        automationRate: 'k-rate',
      },
      {
        name: 'velocity',
        defaultValue: 100, // ? normalize ?
        minValue: 0,
        maxValue: 127,
        automationRate: 'k-rate',
      },
      {
        name: 'playbackRate',
        defaultValue: 1,
        minValue: 0.1,
        maxValue: 8,
        automationRate: 'k-rate',
      },
      {
        name: 'loopStart',
        defaultValue: 0, // normalized
        minValue: 0,
        maxValue: 1,
        automationRate: 'k-rate',
      },
      {
        name: 'loopEnd',
        defaultValue: 1, // normalized
        minValue: 0,
        maxValue: 1,
        automationRate: 'k-rate',
      },
      {
        name: 'startPoint',
        defaultValue: 0, // normalized
        minValue: 0,
        maxValue: 1,
        automationRate: 'k-rate',
      },
      {
        name: 'endPoint',
        defaultValue: 1, // normalized
        minValue: 0,
        maxValue: 1,
        automationRate: 'k-rate',
      },
    ];
  }

  // ===== CONSTRUCTOR =====

  constructor() {
    super();

    this.buffer = null;

    this.playbackPosition = 0;
    this.loopCount = 0;
    this.maxLoopCount = Number.MAX_SAFE_INTEGER;

    // Timing state
    this.isPlaying = false;
    this.startTime = 0; // When playback started
    this.startPoint = 0; // Starting position in seconds
    this.scheduledEndTime = null; // When playback should end (if duration specified)

    // Zero crossing constraints
    this.minZeroCrossing = 0;
    this.maxZeroCrossing = 0;

    // Other flags
    this.isReleasing = false;
    this.loopEnabled = false;
    this.usePlaybackPosition = false;

    // Cache quantized values per process block
    this.blockQuantizedLoopStart = 0;
    this.blockQuantizedLoopEnd = 0;
    this.lastProcessedLoopStart = -1;
    this.lastProcessedLoopEnd = -1;

    this.port.onmessage = this.#handleMessage.bind(this);

    this.debugCounter = 0;
  }

  // ===== MESSAGE HANDLING =====

  #handleMessage(event) {
    const { type, value, buffer, startPoint, duration, when, zeroCrossings } =
      event.data;

    switch (type) {
      case 'voice:init':
        this.#resetState();

        this.port.postMessage({ type: 'initialized' });
        break;

      case 'voice:set_buffer':
        this.#resetState();
        this.buffer = null;
        this.buffer = buffer;

        this.port.postMessage({
          type: 'voice:loaded',
          duration: duration,
          time: currentTime,
        });
        break;

      case 'voice:set_zero_crossings':
        this.zeroCrossings = (zeroCrossings || []).map(
          (timeSec) => timeSec * sampleRate
        );

        // Set min/max zero crossings for parameter constraints
        if (this.zeroCrossings.length > 0) {
          this.minZeroCrossing = this.zeroCrossings[0];
          this.maxZeroCrossing =
            this.zeroCrossings[this.zeroCrossings.length - 1];
        }
        break;

      case 'voice:start':
        this.isReleasing = false;
        this.isPlaying = true;
        this.loopCount = 0;
        this.startTime = when || currentTime;

        // will be set in process() using parameters
        this.playbackPosition = 0;

        this.port.postMessage({
          type: 'voice:started',
          time: currentTime,
        });
        break;

      case 'voice:release':
        this.isReleasing = true;

        this.port.postMessage({
          type: 'voice:releasing',
          time: currentTime,
        });
        break;

      case 'voice:stop':
        this.#stop();
        break;

      case 'setLoopEnabled':
        this.loopEnabled = value;

        this.port.postMessage({
          type: 'loop:enabled',
        });
        break;

      case 'voice:usePlaybackPosition':
        this.usePlaybackPosition = value;
        break;
    }
  }

  // ===== METHODS =====

  #resetState() {
    this.isPlaying = false;
    this.isReleasing = false;
    this.startTime = 0;
    this.startPoint = 0;
    this.scheduledEndTime = null;
    this.playbackPosition = 0;
    this.loopCount = 0;
    this.maxLoopCount = Number.MAX_SAFE_INTEGER;
  }

  #stop() {
    this.isPlaying = false;
    this.isReleasing = false;
    this.playbackPosition = 0;
    this.port.postMessage({ type: 'voice:stopped' });
  }

  #clamp = (value, min, max) => Math.max(min, Math.min(max, value));

  #clampZeroCrossing = (value) =>
    this.#clamp(value, this.minZeroCrossing, this.maxZeroCrossing);

  #findNearestZeroCrossing(position, maxDistance = null) {
    if (!this.zeroCrossings || this.zeroCrossings.length === 0) {
      return position;
    }

    // Find closest zero crossing
    const closest = this.zeroCrossings.reduce(
      (prev, curr) =>
        Math.abs(curr - position) < Math.abs(prev - position) ? curr : prev,
      this.zeroCrossings[0]
    );

    // If maxDistance specified and closest is too far, use original position
    if (maxDistance !== null && Math.abs(closest - position) > maxDistance) {
      return position;
    }

    return closest;
  }

  // ===== CONVERSION UTILITIES =====

  /**
   * Convert normalized position (0-1) to sample index
   * @param {number} normalizedPosition - Position as 0-1 value
   * @returns {number} - Sample index
   */
  #normalizedToSamples(normalizedPosition) {
    if (!this.buffer || !this.buffer[0]) return 0;
    return normalizedPosition * this.buffer[0].length;
  }

  /**
   * Convert sample index to normalized position (0-1)
   * @param {number} sampleIndex - Sample index
   * @returns {number} - Normalized position 0-1
   */
  #samplesToNormalized(sampleIndex) {
    if (!this.buffer || !this.buffer[0]) return 0;
    return sampleIndex / this.buffer[0].length;
  }

  /**
   * Convert normalized time (0-1) to absolute seconds based on buffer duration
   * @param {number} normalizedTime - Time as 0-1 value
   * @returns {number} - Time in seconds
   */
  #normalizedToSeconds(normalizedTime) {
    if (!this.buffer || !this.buffer[0]) return 0;
    const bufferDurationSec = this.buffer[0].length / sampleRate;
    return normalizedTime * bufferDurationSec;
  }

  /**
   * Convert MIDI velocity (0-127) to gain multiplier (0-1)
   * @param {number} midiVelocity - MIDI velocity 0-127
   * @returns {number} - Gain multiplier 0-1
   */
  #midiVelocityToGain(midiVelocity) {
    return Math.max(0, Math.min(1, midiVelocity / 127));
  }

  /**
   * Get buffer length in samples
   * @returns {number} - Buffer length in samples
   */
  #getBufferLengthSamples() {
    return this.buffer?.[0]?.length || 0;
  }

  /**
   * Get buffer duration in seconds
   * @returns {number} - Buffer duration in seconds
   */
  #getBufferDurationSeconds() {
    return this.#getBufferLengthSamples() / sampleRate;
  }

  /**
   * Extract and convert all position parameters from normalized to samples
   * @param {Object} parameters - AudioWorkletProcessor parameters
   * @returns {Object} - Converted parameters in samples
   */
  #extractPositionParams(parameters) {
    const samples = {
      startPointSamples: this.#normalizedToSamples(parameters.startPoint[0]),
      endPointSamples: this.#normalizedToSamples(parameters.endPoint[0]),
      loopStartSamples: this.#normalizedToSamples(parameters.loopStart[0]),
      loopEndSamples: this.#normalizedToSamples(parameters.loopEnd[0]),
    };

    // console.info(
    //   'Raw loopEnd parameter:',
    //   parameters.loopEnd[0],
    //   'normalizedToSamples:',
    //   samples.loopEndSamples
    // );

    // console.log('DEBUG parameter arrays:', {
    //   loopEndArray: parameters.loopEnd,
    //   loopEndLength: parameters.loopEnd?.length,
    //   loopStartArray: parameters.loopStart,
    //   loopStartLength: parameters.loopStart?.length,
    // });

    return samples;
  }

  /**
   * Calculate effective playback range in samples
   * @param {Object} params - Position parameters from #extractPositionParams
   * @returns {Object} - Effective start and end positions
   */
  #calculatePlaybackRange(params) {
    const bufferLength = this.#getBufferLengthSamples();

    const effectiveStart = Math.max(0, params.startPointSamples);
    const effectiveEnd =
      params.endPointSamples > 0
        ? Math.min(bufferLength, params.endPointSamples)
        : bufferLength;

    return {
      startSamples: effectiveStart, // ← Must be actual sample indices
      endSamples: effectiveEnd, // ← Must be actual sample indices
      durationSamples: effectiveEnd - effectiveStart,
    };
  }

  /**
   * Calculate effective loop range in samples
   * @param {Object} params - Position parameters from #extractPositionParams
   * @param {Object} playbackRange - Range from #calculatePlaybackRange
   * @returns {Object} - Effective loop start and end positions
   */
  #calculateLoopRange(params, playbackRange, originalParams) {
    const lpStart = params.loopStartSamples;
    const lpEnd = params.loopEndSamples;

    // Default to playback range if loop points are not set

    let safeLoopStart =
      lpStart < lpEnd && lpStart >= 0 ? lpStart : playbackRange.startSamples;

    const bufferLengthSamples = this.#getBufferLengthSamples();

    let safeLoopEnd =
      lpEnd > lpStart && lpEnd <= bufferLengthSamples
        ? lpEnd
        : playbackRange.endSamples;

    // if (this.loopEnabled && this.debugCounter % 1000 === 0) {
    //   console.error(
    //     lpEnd > lpStart && lpEnd <= bufferLengthSamples,
    //     playbackRange.endSamples,
    //     lpEnd
    //   );
    //   console.log('Raw loopEnd param:', originalParams.loopEnd[0]);
    // }

    return {
      startSamples: safeLoopStart,
      endSamples: safeLoopEnd,
      durationSamples: safeLoopEnd - safeLoopStart,
    };
  }

  // ===== MAIN PROCESS METHOD =====

  process(inputs, outputs, parameters) {
    const output = outputs[0];

    if (!output || !this.isPlaying || !this.buffer) {
      return true;
    }

    // If this is the first process call after starting playback,
    // initialize playback position using startPoint
    if (this.playbackPosition === 0) {
      const startPointSec = parameters.startPoint[0];
      this.playbackPosition = startPointSec * sampleRate;
    }

    const pbRate = parameters.playbackRate[0];

    // Get start and end points from parameters and convert to samples
    const startPointSec = parameters.startPoint[0];
    const endPointSec = parameters.endPoint[0];

    // Convert to samples
    const startPointSamples = startPointSec * sampleRate;

    // Handle end point - if endPoint is set (greater than 0), use it to limit playback
    const bufferLength = this.buffer[0].length;
    let effectiveBufferEnd = bufferLength;
    if (endPointSec > 0) {
      effectiveBufferEnd = Math.min(bufferLength, endPointSec * sampleRate);
    }

    // Quantize once per block, not per sample
    const rawLoopStart = parameters.loopStart[0] * sampleRate;
    const rawLoopEnd = parameters.loopEnd[0] * sampleRate;

    const loopStart = rawLoopStart;
    const loopEnd = rawLoopEnd;

    const constrainedLoopEnd = Math.min(loopEnd, effectiveBufferEnd);

    const envelopeGain = parameters.envGain[0];
    const velocitySensitivity = 0.9;
    const normalizedVelocity = parameters.velocity[0] / 127; // this.#normalizeMidi(parameters.velocity[0]);
    const velocityGain = normalizedVelocity * velocitySensitivity;

    const numChannels = Math.min(output.length, this.buffer.length);

    // Process samples
    for (let i = 0; i < output[0].length; i++) {
      // Handle looping
      if (
        this.loopEnabled &&
        this.playbackPosition >= constrainedLoopEnd &&
        this.loopCount < this.maxLoopCount
      ) {
        this.playbackPosition = loopStart;
        this.loopCount++;
      }

      // Check for end of buffer or effective end position
      if (this.playbackPosition >= effectiveBufferEnd) {
        this.#stop(output);
        return true;
      }

      // Read and interpolate samples
      const position = Math.floor(this.playbackPosition);
      const fraction = this.playbackPosition - position;
      const nextPosition = Math.min(position + 1, effectiveBufferEnd - 1);

      for (let c = 0; c < numChannels; c++) {
        const bufferChannel = this.buffer[Math.min(c, this.buffer.length - 1)];
        const current = bufferChannel[position];
        const next = bufferChannel[nextPosition];

        // output[c][i] =
        //   (current + fraction * (next - current)) * velocityGain * envelopeGain;

        const sample =
          (current + fraction * (next - current)) * velocityGain * envelopeGain;

        output[c][i] = Math.max(-1, Math.min(1, isFinite(sample) ? sample : 0));
      }
      // Advance playback position
      this.playbackPosition += pbRate;
    }

    if (this.usePlaybackPosition) {
      this.port.postMessage({
        type: 'voice:position',
        position: this.playbackPosition / sampleRate,
      });
    }

    return true;
  }

  // // ===== USE EXPLICIT CONVERSION UTILITIES =====
  // const positionParams = this.#extractPositionParams(parameters);
  // const playbackRange = this.#calculatePlaybackRange(positionParams);
  // const loopRange = this.#calculateLoopRange(
  //   positionParams,
  //   playbackRange,
  //   parameters
  // );

  // // Initialize playback position on first process call
  // if (this.playbackPosition === 0) {
  //   this.playbackPosition = playbackRange.startSamples;
  // }

  //     // ===== AUDIO PROCESSING =====
  //     const playbackRate = parameters.playbackRate[0];
  //     const envelopeGain = parameters.envGain[0];
  //     const velocityGain = this.#midiVelocityToGain(parameters.velocity[0]);

  //     const velocitySensitivity = 0.9;
  //     const finalVelocityGain = velocityGain * velocitySensitivity;

  //     const numChannels = Math.min(output.length, this.buffer.length);

  //     // === DEBUGGING REMOVE ===

  //     if (this.loopEnabled && this.debugCounter % 1000 === 0) {
  //       // console.log('Raw parameter values received:', {
  //       //   loopStart: parameters.loopStart[0],
  //       //   loopEnd: parameters.loopEnd[0],
  //       //   currentTime: currentTime,
  //       // });
  //       // console.log('Loop logic debug:', {
  //       //   playbackPosition: this.playbackPosition,
  //       //   loopRangeStart: loopRange.startSamples,
  //       //   loopRangeEnd: loopRange.endSamples,
  //       //   playbackRangeEnd: playbackRange.endSamples,
  //       //   parametersLoopStart: parameters.loopStart[0],
  //       //   parametersLoopEnd: parameters.loopEnd[0],
  //       //   willLoop: this.playbackPosition >= loopRange.endSamples,
  //       // });

  //       this.port.postMessage({
  //         type: 'debug:params',
  //         loopStartRaw: parameters.loopStart[0],
  //         loopStartSamples: this.#normalizedToSamples(parameters.loopStart[0]),
  //         loopEndRaw: parameters.loopEnd[0],
  //         loopEndSamples: this.#normalizedToSamples(parameters.loopEnd[0]),
  //       });
  //     }

  //     // Process each sample
  //     for (let i = 0; i < output[0].length; i++) {
  //       // Handle looping
  //       if (
  //         this.loopEnabled &&
  //         this.playbackPosition >= loopRange.endSamples
  //         // &&
  //         // this.loopCount < this.maxLoopCount
  //       ) {
  //         this.playbackPosition = loopRange.startSamples;
  //         this.loopCount++;

  //         this.port.postMessage({ type: 'voice:looped', count: this.loopCount });
  //       }

  //       // Check for end of playback range
  //       if (this.playbackPosition >= playbackRange.endSamples) {
  //         this.#stop();
  //         return true;
  //       }

  //       // Sample interpolation
  //       const position = Math.floor(this.playbackPosition);
  //       const fraction = this.playbackPosition - position;
  //       const nextPosition = Math.min(position + 1, playbackRange.endSamples - 1);

  //       // Generate output for each channel
  //       for (let c = 0; c < numChannels; c++) {
  //         const bufferChannel = this.buffer[Math.min(c, this.buffer.length - 1)];
  //         const current = bufferChannel[position] || 0;
  //         const next = bufferChannel[nextPosition] || 0;

  //         const interpolatedSample = current + fraction * (next - current);
  //         const finalSample =
  //           interpolatedSample * finalVelocityGain * envelopeGain;

  //         output[c][i] = Math.max(
  //           -1,
  //           Math.min(1, isFinite(finalSample) ? finalSample : 0)
  //         );
  //       }

  //       this.playbackPosition += playbackRate;
  //     }

  //     // Send position updates if requested
  //     if (this.usePlaybackPosition) {
  //       const normalizedPosition = this.#samplesToNormalized(
  //         this.playbackPosition
  //       );
  //       this.port.postMessage({
  //         type: 'voice:position',
  //         position: normalizedPosition,
  //       });
  //     }

  //     return true;
  //   }
}

registerProcessor('sample-player-processor', SamplePlayerProcessor);
